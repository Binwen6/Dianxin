# SenseVoice æ™ºèƒ½è¯­éŸ³è½¬æ–‡å­—å¤„ç†å™¨ v2.0

> ğŸš€ **ä¸‹ä¸€ä»£è¯­éŸ³è½¬æ–‡å­—å·¥ä½œæµå¤„ç†å™¨** - æ”¯æŒéŸ³é¢‘/è§†é¢‘å¤„ç†ã€GPUå¹¶è¡Œè®¡ç®—ã€æ™ºèƒ½åˆ†å‰²å’ŒAIå†…å®¹çº é”™

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![SenseVoice](https://img.shields.io/badge/SenseVoice-Small-green.svg)](https://github.com/alibaba-damo-academy/FunASR)
[![GPU](https://img.shields.io/badge/GPU-CUDA%20æ”¯æŒ-orange.svg)](https://developer.nvidia.com/cuda-zone)
[![License](https://img.shields.io/badge/License-MIT-red.svg)](LICENSE)

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ **æ™ºèƒ½å¤„ç†èƒ½åŠ›**
- **ğŸ¬ è§†é¢‘éŸ³é¢‘ä¸€ä½“åŒ–**: è‡ªåŠ¨ä»è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘å¹¶è½¬å†™
- **ğŸ§  æ™ºèƒ½åˆ†å‰²æŠ€æœ¯**: é•¿éŸ³é¢‘è‡ªåŠ¨åˆ†å‰²ï¼Œæœ€ä¼˜åŒ–å¹¶è¡Œå¤„ç†ç­–ç•¥
- **ğŸ”§ AIå†…å®¹çº é”™**: é›†æˆé€šä¹‰åƒé—®APIï¼Œæ™ºèƒ½çº é”™å’Œä¼˜åŒ–è½¬å†™ç»“æœ
- **âš¡ GPUå¹¶è¡Œè®¡ç®—**: æ”¯æŒå¤šè¿›ç¨‹GPUå¹¶è¡Œå¤„ç†ï¼Œå¤§å¹…æå‡å¤„ç†é€Ÿåº¦

### ğŸš€ **é«˜æ€§èƒ½æ¶æ„**
- **ğŸ“Š å¤šå±‚æ¬¡å¹¶è¡Œ**: æ–‡ä»¶çº§ + åˆ†æ®µçº§åŒé‡å¹¶è¡Œå¤„ç†
- **ğŸ›ï¸ æ™ºèƒ½è´Ÿè½½å‡è¡¡**: æ ¹æ®éŸ³é¢‘æ—¶é•¿è‡ªåŠ¨è°ƒæ•´å¤„ç†ç­–ç•¥
- **ğŸ’¾ å†…å­˜ä¼˜åŒ–**: æ™ºèƒ½æ¨¡å‹åŠ è½½å’Œèµ„æºç®¡ç†
- **ğŸ“ˆ æ€§èƒ½ç›‘æ§**: å®æ—¶å¤„ç†æ•ˆç‡åˆ†æå’Œä¼˜åŒ–å»ºè®®

### ğŸ¨ **å·¥ä½œæµé›†æˆ**
- **ğŸ”— æ ‡å‡†åŒ–æ¥å£**: å®Œç¾é€‚é…è§†é¢‘è½¬éŸ³é¢‘ â†’ è¯­éŸ³è½¬æ–‡å­— â†’ æ–‡å­—è½¬PPTå·¥ä½œæµ
- **ğŸ“‹ å¤šæ ¼å¼è¾“å‡º**: JSONã€TXTã€å·¥ä½œæµå…ƒæ•°æ®ç­‰å¤šç§æ ¼å¼
- **ğŸ• æ—¶é—´æˆ³æ”¯æŒ**: ç²¾ç¡®çš„æ®µè½å’Œå¥å­çº§æ—¶é—´æˆ³
- **ğŸ“ æ‰¹é‡å¤„ç†**: ç›®å½•çº§æ‰¹é‡å¤„ç†ï¼Œæ”¯æŒæ··åˆéŸ³é¢‘/è§†é¢‘æ–‡ä»¶

## ğŸ“¦ å®‰è£…ä¾èµ–

### æ ¸å¿ƒä¾èµ–
```bash
pip install -r requirements.txt
```

### ç³»ç»Ÿä¾èµ– (ffmpeg)
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install ffmpeg

# Windows
# ä» https://ffmpeg.org/download.html ä¸‹è½½å¹¶æ·»åŠ åˆ°PATH
```

### GPUæ”¯æŒ (å¯é€‰)
```bash
# CUDA 11.8+
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç”¨æ³•

```python
from video_to_text import WorkflowSpeechProcessor, process_audio_for_workflow

# æ–¹æ³•1: ç®€å•å¤„ç†
result = process_audio_for_workflow(
    audio_input="path/to/audio.mp3",  # æ”¯æŒéŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶
    output_dir="output",
    config={
        'device': 'cuda:0',
        'enable_dashscope_correction': True,
        'parallel_processing': True
    }
)

# æ–¹æ³•2: é«˜çº§é…ç½®
processor = WorkflowSpeechProcessor({
    'device': 'cuda:0',
    'parallel_processing': True,
    'enable_smart_segmentation': True,
    'enable_dashscope_correction': True,
    'max_workers': 4
})

result = processor.process_single_audio("video.mp4")
print(f"è½¬å†™ç»“æœ: {result['transcription']}")
```

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# ğŸµ å¤„ç†éŸ³é¢‘æ–‡ä»¶
python video_to_text.py audio.mp3 -o output --enable-correction

# ğŸ¬ å¤„ç†è§†é¢‘æ–‡ä»¶  
python video_to_text.py video.mp4 -o output --device cuda:0

# ğŸ“ æ‰¹é‡å¤„ç†ç›®å½•
python video_to_text.py /path/to/media/directory -o output --parallel

# ğŸ”§ é«˜çº§é…ç½®
python video_to_text.py input.mp4 \
    --device cuda:0 \
    --enable-correction \
    --max-workers 4 \
    --video-audio-quality 2 \
    --dashscope-model qwen-turbo

# ğŸ“Š æŸ¥çœ‹é…ç½®ä¿¡æ¯
python video_to_text.py --show-config
```

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### ğŸ›ï¸ åŸºç¡€é…ç½®

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `device` | `auto` | å¤„ç†è®¾å¤‡ (`cuda:0`, `cpu`, `auto`) |
| `language` | `auto` | è¯­è¨€è®¾ç½® (`auto`, `zh`, `en`, `ja`, `ko`) |
| `model_dir` | `iic/SenseVoiceSmall` | SenseVoiceæ¨¡å‹è·¯å¾„ |

### âš¡ å¹¶è¡Œå¤„ç†é…ç½®

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `parallel_processing` | `True` | å¯ç”¨å¹¶è¡Œå¤„ç† |
| `max_workers` | `4` | æœ€å¤§å·¥ä½œè¿›ç¨‹æ•° |
| `enable_smart_segmentation` | `True` | æ™ºèƒ½åˆ†å‰²é•¿éŸ³é¢‘ |
| `processing_time_ratio` | `1/17` | å¤„ç†æ—¶é—´æ¯”ç‡ (ç ”ç©¶ä¼˜åŒ–ç»“æœ) |

### ğŸ§  AIå†…å®¹çº é”™é…ç½®

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `enable_dashscope_correction` | `False` | å¯ç”¨é€šä¹‰åƒé—®çº é”™ |
| `dashscope_model` | `qwen-turbo` | ä½¿ç”¨çš„é€šä¹‰åƒé—®æ¨¡å‹ |
| `dashscope_temperature` | `0.1` | æ¸©åº¦å‚æ•° (0.0-2.0) |
| `dashscope_max_tokens` | `10000` | æœ€å¤§tokenæ•° |

### ğŸ¬ è§†é¢‘å¤„ç†é…ç½®

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `video_audio_quality` | `4` | éŸ³é¢‘æå–è´¨é‡ (0-9, 0æœ€é«˜è´¨é‡) |
| `cleanup_extracted_audio` | `False` | å¤„ç†åæ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ |

## ğŸ”§ é«˜çº§åŠŸèƒ½

### ğŸ§  æ™ºèƒ½åˆ†å‰²ç®—æ³•

ç³»ç»Ÿé‡‡ç”¨åŸºäºç ”ç©¶ä¼˜åŒ–çš„æ™ºèƒ½åˆ†å‰²ç®—æ³•ï¼š

```python
# æœ€ä¼˜åˆ†å‰²æ®µæ•°è®¡ç®—å…¬å¼
optimal_segments = sqrt(audio_duration * processing_time_ratio / 7)

# è‡ªåŠ¨æ¿€æ´»æ¡ä»¶
if optimal_segments > 2 and audio_duration > 600:
    use_smart_segmentation = True
```

**æ™ºèƒ½åˆ†å‰²ä¼˜åŠ¿:**
- ğŸ“Š æ ¹æ®éŸ³é¢‘æ—¶é•¿è‡ªåŠ¨è®¡ç®—æœ€ä¼˜åˆ†å‰²ç­–ç•¥
- ğŸ”„ åˆ†æ®µé‡å å¤„ç†ï¼Œç¡®ä¿å†…å®¹å®Œæ•´æ€§
- âš–ï¸ å¹³è¡¡å¹¶è¡Œæ•ˆç‡ä¸æ¨¡å‹åŠ è½½å¼€é”€

### ğŸš€ GPUå¹¶è¡Œå¤„ç†

æ”¯æŒå¤šç§å¹¶è¡Œå¤„ç†æ¨¡å¼ï¼š

1. **æ–‡ä»¶çº§å¹¶è¡Œ**: å¤šä¸ªéŸ³é¢‘æ–‡ä»¶åŒæ—¶å¤„ç†
2. **åˆ†æ®µçº§å¹¶è¡Œ**: å•ä¸ªé•¿éŸ³é¢‘åˆ†å‰²åå¹¶è¡Œå¤„ç†
3. **æ··åˆå¹¶è¡Œ**: åŒæ—¶æ”¯æŒæ–‡ä»¶çº§å’Œåˆ†æ®µçº§å¹¶è¡Œ

```python
# GPUå¹¶è¡Œé…ç½®ç¤ºä¾‹
config = {
    'device': 'cuda:0',
    'parallel_processing': True,
    'max_workers': 4,  # æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´
    'enable_smart_segmentation': True
}
```

### ğŸ” AIå†…å®¹çº é”™

é›†æˆé˜¿é‡Œäº‘é€šä¹‰åƒé—®APIï¼Œæä¾›æ™ºèƒ½å†…å®¹çº é”™ï¼š

```python
# å¯ç”¨AIçº é”™
config = {
    'enable_dashscope_correction': True,
    'dashscope_api_key': 'your_api_key',
    'dashscope_model': 'qwen-turbo',
    'dashscope_temperature': 0.1
}
```

**çº é”™åŠŸèƒ½:**
- âœ… è¯­æ³•é”™è¯¯ä¿®æ­£
- âœ… æ ‡ç‚¹ç¬¦å·ä¼˜åŒ–
- âœ… åŒéŸ³å­—çº é”™
- âœ… è¯­ä¹‰è¿è´¯æ€§æå‡

## ğŸ“‹ è¾“å‡ºæ ¼å¼

### ğŸ“„ æ ‡å‡†transcripts.jsonæ ¼å¼

```json
{
  "metadata": {
    "total_files": 1,
    "successful_transcriptions": 1,
    "total_words": 150,
    "total_characters": 300,
    "total_audio_duration": 45.2,
    "processing_time": 5.5,
    "model_used": "iic/SenseVoiceSmall",
    "device_used": "cuda:0",
    "workflow_step": "speech2text",
    "timestamp": "2024-01-15T10:30:45"
  },
  "transcripts": [
    {
      "file_name": "audio.mp3",
      "status": "success",
      "transcription": "è½¬å†™çš„å®Œæ•´æ–‡æœ¬å†…å®¹...",
      "processing_time": 5.5,
      "word_count": 150,
      "character_count": 300,
      "audio_duration": 45.2,
      "segments": [
        {
          "text": "è¿™æ˜¯ç¬¬ä¸€æ®µå†…å®¹",
          "start": 0.0,
          "end": 8.2,
          "duration": 8.2
        }
      ],
      "metadata": {
        "model_used": "iic/SenseVoiceSmall",
        "device": "cuda:0",
        "input_type": "video",
        "extraction_successful": true,
        "segmentation_info": {
          "total_segments": 3,
          "successful_segments": 3,
          "segmentation_method": "smart_segmentation"
        },
        "dashscope_correction": {
          "enabled": true,
          "correction_time": 1.2,
          "text_changed": true
        }
      }
    }
  ]
}
```

### ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„

```
output/
â”œâ”€â”€ audio_name/                    # æ¯ä¸ªéŸ³é¢‘çš„ç‹¬ç«‹ç›®å½•
â”‚   â”œâ”€â”€ transcripts.json           # æ ‡å‡†æ ¼å¼è½¬å†™ç»“æœ
â”‚   â”œâ”€â”€ audio_name_result.json     # è¯¦ç»†å¤„ç†ç»“æœ
â”‚   â””â”€â”€ audio_name_content.txt     # çº¯æ–‡æœ¬å†…å®¹
â”œâ”€â”€ all_transcripts.json           # æ‰€æœ‰æ–‡ä»¶çš„æ±‡æ€»ç»“æœ
â”œâ”€â”€ all_content_20240115_103045.txt # æ±‡æ€»æ–‡æœ¬å†…å®¹
â”œâ”€â”€ batch_results_20240115_103045.json # æ‰¹å¤„ç†ç»“æœ
â””â”€â”€ workflow_metadata_20240115_103045.json # å·¥ä½œæµå…ƒæ•°æ®
```

## ğŸ¯ æ”¯æŒçš„æ ¼å¼

### ğŸµ éŸ³é¢‘æ ¼å¼
`.mp3`, `.wav`, `.m4a`, `.flac`, `.aac`, `.ogg`, `.wma`

### ğŸ¬ è§†é¢‘æ ¼å¼  
`.mp4`, `.avi`, `.mkv`, `.mov`, `.wmv`, `.flv`, `.webm`, `.m4v`, `.3gp`, `.3g2`, `.asf`, `.rm`, `.rmvb`, `.vob`, `.ts`, `.mts`, `.m2ts`, `.f4v`, `.divx`, `.xvid`, `.ogv`

## ğŸ”§ æ•…éšœæ’é™¤

### ğŸš¨ å¸¸è§é—®é¢˜

#### GPUå†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆ1: å‡å°‘å¹¶å‘æ•°
python video_to_text.py input.mp4 --max-workers 2

# è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨CPUæ¨¡å¼
python video_to_text.py input.mp4 --device cpu

# è§£å†³æ–¹æ¡ˆ3: ç¦ç”¨å¹¶è¡Œå¤„ç†
python video_to_text.py input.mp4 --no-parallel
```

#### æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
python video_to_text.py --show-config

# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
# æ¨¡å‹ä¼šè‡ªåŠ¨ä»HuggingFaceä¸‹è½½åˆ°ç¼“å­˜ç›®å½•
```

#### ffmpegæœªå®‰è£…
```bash
# æ£€æŸ¥ffmpegçŠ¶æ€
python video_to_text.py --show-config

# å®‰è£…ffmpeg (è§å®‰è£…ä¾èµ–éƒ¨åˆ†)
```

### ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **GPUæ¨¡å¼ä¸‹çš„æœ€ä½³å®è·µ:**
   - å•GPU: `max_workers=2-4`
   - å¤šGPU: é…ç½®ä¸åŒçš„`cuda:0`, `cuda:1`è®¾å¤‡

2. **é•¿éŸ³é¢‘å¤„ç†ä¼˜åŒ–:**
   - å¯ç”¨æ™ºèƒ½åˆ†å‰²: `--enable-smart-seg`
   - è°ƒæ•´åˆ†å‰²å‚æ•°: `min_segment_duration=30`

3. **æ‰¹é‡å¤„ç†ä¼˜åŒ–:**
   - å°æ–‡ä»¶(<4ä¸ª): è‡ªåŠ¨ä½¿ç”¨ä¸²è¡Œå¤„ç†
   - å¤§æ–‡ä»¶æ‰¹é‡: å¯ç”¨å¹¶è¡Œå¤„ç†

## ğŸ”— å·¥ä½œæµé›†æˆ

### ğŸ“¥ ä¸Šæ¸¸é›†æˆ (è§†é¢‘è½¬éŸ³é¢‘)

```python
# æ¥æ”¶æ¥è‡ªè§†é¢‘å¤„ç†æ¨¡å—çš„æ•°æ®
upstream_data = {
    'step_name': 'video2audio',
    'output_directory': 'extracted_audios/',
    'video_files': ['video1.mp4', 'video2.mp4'],
    'workflow_id': 'workflow_001'
}

# å¤„ç†éŸ³é¢‘è½¬å†™
result = process_audio_for_workflow(
    audio_input=upstream_data['output_directory'],
    workflow_id=upstream_data['workflow_id']
)
```

### ğŸ“¤ ä¸‹æ¸¸é›†æˆ (æ–‡å­—è½¬PPT)

```python
# ä¸ºPPTç”Ÿæˆæ¨¡å—å‡†å¤‡æ•°æ®
def prepare_for_ppt_generator(transcripts_data):
    return {
        'workflow_step': 'text2ppt',
        'content_type': 'transcription',
        'slides': [
            {
                'slide_number': i+1,
                'title': f"éŸ³é¢‘è½¬å†™: {transcript['file_name']}",
                'content': transcript['transcription'],
                'word_count': transcript['word_count']
            }
            for i, transcript in enumerate(transcripts_data['transcripts'])
        ],
        'metadata': transcripts_data['metadata']
    }

# ä¼ é€’ç»™PPTç”Ÿæˆæ¨¡å—
ppt_data = prepare_for_ppt_generator(result)
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### âš¡ å¤„ç†é€Ÿåº¦

| éŸ³é¢‘æ—¶é•¿ | CPUæ¨¡å¼ | GPUæ¨¡å¼ | GPUå¹¶è¡Œæ¨¡å¼ |
|----------|---------|---------|-------------|
| 1åˆ†é’Ÿ | ~6s | ~3s | ~2s |
| 10åˆ†é’Ÿ | ~60s | ~35s | ~12s |
| 60åˆ†é’Ÿ | ~600s | ~350s | ~80s |

### ğŸ’¾ èµ„æºå ç”¨

| æ¨¡å¼ | GPUæ˜¾å­˜ | ç³»ç»Ÿå†…å­˜ | CPUä½¿ç”¨ç‡ |
|------|---------|----------|-----------|
| å•è¿›ç¨‹ | ~2GB | ~1GB | 50% |
| å¹¶è¡Œ(4è¿›ç¨‹) | ~6GB | ~3GB | 90% |

## ğŸ¤ è´¡çŒ®æŒ‡å—

### ğŸ› é—®é¢˜æŠ¥å‘Š

å‘ç°é—®é¢˜è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼æŠ¥å‘Š:
1. è¯¦ç»†æè¿°é—®é¢˜ç°è±¡
2. æä¾›å¤ç°æ­¥éª¤å’Œç¤ºä¾‹æ–‡ä»¶
3. åŒ…å«ç³»ç»Ÿç¯å¢ƒä¿¡æ¯ (`--show-config`)

### ğŸš€ åŠŸèƒ½å»ºè®®

æ¬¢è¿æå‡ºæ–°åŠŸèƒ½å»ºè®®:
- æ–°çš„è¯­éŸ³æ¨¡å‹æ”¯æŒ
- æ›´å¤šè¾“å‡ºæ ¼å¼
- æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“š APIæ–‡æ¡£

### æ ¸å¿ƒç±»: WorkflowSpeechProcessor

```python
class WorkflowSpeechProcessor:
    def __init__(self, config: Optional[Dict[str, Any]] = None)
    def process_single_audio(self, audio_path: Union[str, Path]) -> Dict[str, Any]
    def process_audio_directory(self, audio_dir: Union[str, Path]) -> Dict[str, Any]
    def get_workflow_status(self) -> Dict[str, Any]
```

### ä¾¿æ·å‡½æ•°

```python
def process_audio_for_workflow(
    audio_input: Union[str, Path], 
    output_dir: Optional[Union[str, Path]] = None,
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]
```

## ğŸ“œ æ›´æ–°æ—¥å¿—

### v2.0.0 (2024-01-15)
- âœ¨ æ–°å¢è§†é¢‘æ–‡ä»¶ç›´æ¥å¤„ç†æ”¯æŒ
- âš¡ å®ç°GPUå¹¶è¡Œå¤„ç†æ¶æ„
- ğŸ§  é›†æˆé€šä¹‰åƒé—®AIå†…å®¹çº é”™
- ğŸ“Š æ™ºèƒ½åˆ†å‰²ç®—æ³•ä¼˜åŒ–
- ğŸ”§ å…¨é¢é‡æ„é…ç½®ç³»ç»Ÿ

### v1.x.x
- åŸºç¡€éŸ³é¢‘è½¬å†™åŠŸèƒ½
- æ‰¹é‡å¤„ç†æ”¯æŒ
- æ—¶é—´æˆ³ç”Ÿæˆ

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

- [FunASR](https://github.com/alibaba-damo-academy/FunASR) - SenseVoiceæ¨¡å‹æ”¯æŒ
- [é˜¿é‡Œäº‘é€šä¹‰åƒé—®](https://dashscope.aliyun.com/) - AIå†…å®¹çº é”™æœåŠ¡
- [FFmpeg](https://ffmpeg.org/) - éŸ³è§†é¢‘å¤„ç†æ”¯æŒ

---

**ğŸ’¡ æç¤º**: å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª â­ Starï¼è¿™å¯¹æˆ‘ä»¬éå¸¸é‡è¦ï¼

**ğŸ“ è”ç³»æˆ‘ä»¬**: å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿æäº¤ Issue æˆ– Pull Requestã€‚ 